{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.common import DATASET_NAME_MAP\n",
    "# DATASET_NAME = 'mm_tinyimagenet'\n",
    "DATASET_NAME = 'mm_cifar10'\n",
    "\n",
    "def get_held_out_data(nb_samples, transform, is_train):\n",
    "    train_dataset, test_dataset, _ = DATASET_NAME_MAP[DATASET_NAME]()\n",
    "    dataset = train_dataset if is_train else test_dataset\n",
    "    if transform is not None:\n",
    "        dataset_blurred = deepcopy(dataset)\n",
    "        dataset_blurred.transform2 = transform\n",
    "    y_data = np.array(dataset.dataset.targets)\n",
    "    num_classes = len(np.unique(y_data))\n",
    "    nb_samples_per_class = nb_samples // num_classes\n",
    "    idxs = []\n",
    "    for i in range(num_classes):\n",
    "        idxs_i = np.where(y_data == i)[0]\n",
    "        sampled_idxs_i = np.random.choice(idxs_i, size=nb_samples_per_class, replace=False)\n",
    "        idxs.append(sampled_idxs_i)\n",
    "        \n",
    "    idxs = np.concatenate(idxs)\n",
    "    selected_elements = [dataset[i] for i in idxs]\n",
    "    x_data, y_data = zip(*selected_elements)\n",
    "    x_data_left, x_data_right = zip(*x_data)\n",
    "    \n",
    "    x_data_left = torch.stack(x_data_left)\n",
    "    x_data_right = torch.stack(x_data_right)\n",
    "    y_data = torch.tensor(y_data)\n",
    "    \n",
    "    \n",
    "    selected_elements_blurred = [dataset_blurred[i] for i in idxs]\n",
    "    x_data_blurred, y_data = zip(*selected_elements_blurred)\n",
    "    x_data_left_blurred, x_data_right_blurred = zip(*x_data_blurred)\n",
    "    \n",
    "    x_data_left_blurred = torch.stack(x_data_left_blurred)\n",
    "    x_data_right_blurred = torch.stack(x_data_right_blurred)\n",
    "    y_data = torch.tensor(y_data)\n",
    "    \n",
    "    if not os.path.exists('data'):\n",
    "        os.mkdir('data')\n",
    "        \n",
    "    prefix = 'train' if is_train else 'val'\n",
    "                \n",
    "    torch.save(x_data_left, f'data/{prefix}_{DATASET_NAME}_held_out_proper_x_left.pt')\n",
    "    torch.save(x_data_right, f'data/{prefix}_{DATASET_NAME}_held_out_proper_x_right.pt')\n",
    "    torch.save(y_data, f'data/{prefix}_{DATASET_NAME}_held_out_y.pt')\n",
    "    \n",
    "    \n",
    "    # torch.save(x_data_left_blurred, f'data/{DATASET_NAME}_held_out_blurred_x_left.pt')\n",
    "    torch.save(x_data_right_blurred, f'data/{prefix}_{DATASET_NAME}_held_out_blurred_x_right.pt')\n",
    "    # np.save(f'data/{dataset_name}_held_out_x.npy', x_data)\n",
    "    # np.save(f'data/{dataset_name}_held_out_y.npy', y_data)\n",
    "    # return x_data_fellow, x_data_amblyopic, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# TRAIN\n",
    "from src.data.transforms import TRANSFORMS_BLURRED_RIGHT_NAME_MAP\n",
    "transform_blurred = TRANSFORMS_BLURRED_RIGHT_NAME_MAP[DATASET_NAME](0.0)\n",
    "\n",
    "get_held_out_data(nb_samples=1000, transform=transform_blurred, is_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# VAL\n",
    "from src.data import transforms_cifar10\n",
    "transform_blurred = transforms_cifar10.TRANSFORMS_NAME_MAP['transform_eval_blurred'](32, 32, 1/4, 0.0)\n",
    "\n",
    "get_held_out_data(nb_samples=1000, transform=transform_blurred, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = 'mm_cifar10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proper_x_left = torch.load(f'data/{DATASET_NAME}_held_out_proper_x_left.pt')\n",
    "proper_x_right = torch.load(f'data/{DATASET_NAME}_held_out_proper_x_right.pt')\n",
    "blurred_x_right = torch.load(f'data/{DATASET_NAME}_held_out_blurred_x_right.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save indices for corruption experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from src.utils.common import DATASET_NAME_MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = 'mm_cifar10'\n",
    "train_dataset, _, _ = DATASET_NAME_MAP[DATASET_NAME]()\n",
    "y_data = np.array(train_dataset.dataset.targets)\n",
    "nb_samples = int(0.0 * y_data.shape[0])\n",
    "num_classes = len(np.unique(y_data))\n",
    "nb_samples_per_class = nb_samples // num_classes\n",
    "idxs = []\n",
    "for i in range(num_classes):\n",
    "    idxs_i = np.where(y_data == i)[0]\n",
    "    sampled_idxs_i = np.random.choice(idxs_i, size=nb_samples_per_class, replace=False)\n",
    "    idxs.append(sampled_idxs_i)\n",
    "    \n",
    "idxs = np.concatenate(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'data/{DATASET_NAME}_subset_000.npy', idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coś innego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = 'mm_cifar10'\n",
    "def get_indices(nb_samples):\n",
    "    train_dataset, _, _ = DATASET_NAME_MAP[DATASET_NAME]()\n",
    "    y_data = np.array(train_dataset.dataset.targets)\n",
    "    num_classes = len(np.unique(y_data))\n",
    "    nb_samples_per_class = nb_samples // num_classes\n",
    "    idxs = []\n",
    "    for i in range(num_classes):\n",
    "        idxs_i = np.where(y_data == i)[0]\n",
    "        sampled_idxs_i = np.random.choice(idxs_i, size=nb_samples_per_class, replace=False)\n",
    "        idxs.append(sampled_idxs_i)\n",
    "        \n",
    "    idxs = np.concatenate(idxs)\n",
    "    y_data = torch.tensor(idxs)\n",
    "    \n",
    "    if not os.path.exists('data'):\n",
    "        os.mkdir('data')\n",
    "    torch.save(y_data, f'data/train_{DATASET_NAME}_indices.pt')\n",
    "    \n",
    "get_indices(nb_samples=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_data_proper = [transform_train_proper(x) for x in x_data]\n",
    "# x_data_proper = torch.stack(x_data_proper)\n",
    "# y_data_proper = torch.from_numpy(y_data)\n",
    "\n",
    "# torch.save(x_data_proper, f'data/{DATASET_NAME}_held_out_proper_x.pt')\n",
    "# torch.save(y_data_proper, f'data/{DATASET_NAME}_held_out_proper_y.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_data_blurred = [transform_blurred(x) for x in x_data]\n",
    "# x_data_blurred = torch.stack(x_data_blurred)\n",
    "# y_data_blurred = torch.from_numpy(y_data)\n",
    "\n",
    "# torch.save(x_data_blurred, f'data/{DATASET_NAME}_held_out_blurred_x.pt')\n",
    "# torch.save(y_data_blurred, f'data/{DATASET_NAME}_held_out_blurred_y.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = 'proper'\n",
    "path = f'data/{DATASET_NAME}_held_out_{description}_x_fellow.pt'\n",
    "torch.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def show(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = torchvision.utils.make_grid(proper_x_left[:16])\n",
    "show(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = torchvision.utils.make_grid(proper_x_right[:16])\n",
    "show(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = torchvision.utils.make_grid(blurred_x_right[:16])\n",
    "show(grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_histogram(data, bins=10):\n",
    "    plt.hist(data, bins=bins)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 10\n",
    "plot_histogram(torch.flatten(proper_x_right[idx]))\n",
    "plot_histogram(torch.flatten(blurred_x_right[idx]))\n",
    "print((proper_x_right[idx].abs() - blurred_x_right[idx].abs()).sum(), (proper_x_right[idx] - blurred_x_right[idx]).sum()), \n",
    "print(proper_x_right[idx].abs().sum(), proper_x_right[idx].sum(), (proper_x_right[idx] > 0).float().mean()) \n",
    "print(blurred_x_right[idx].abs().sum(), blurred_x_right[idx].sum(), (blurred_x_right[idx] > 0).float().mean())\n",
    "print((proper_x_right[idx].abs() > blurred_x_right[idx].abs()).float().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.utils_model import load_model_specific_params\n",
    "from src.utils.prepare import prepare_model\n",
    "\n",
    "def load_model(model_name, checkpoint_path):\n",
    "    model_params = load_model_specific_params(model_name)\n",
    "    model_params = {\n",
    "        'num_classes': 10,\n",
    "        'input_channels': 3,\n",
    "        'img_height': 32,\n",
    "        'img_width': 32,\n",
    "        'overlap': 00,\n",
    "        **model_params\n",
    "        }\n",
    "        \n",
    "    model = prepare_model(model_name, model_params=model_params)\n",
    "    # model.load_state_dict(torch.load(checkpoint_path, map_location=torch.device('cpu')))\n",
    "    return model\n",
    "\n",
    "# models = []\n",
    "# epochs = [0,20,40,60,80,120,160]\n",
    "\n",
    "model_name = 'mm_resnet'\n",
    "\n",
    "model = load_model(model_name, checkpoint_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv11): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "  (maxpool1): Identity()\n",
       "  (conv21): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "  (maxpool2): Identity()\n",
       "  (left_branch): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Identity()\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (right_branch): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Identity()\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (main_branch): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def change_activation(model, old_activation, new_activation):\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, old_activation):\n",
    "            setattr(model, name, new_activation())\n",
    "        else:\n",
    "            change_activation(module, old_activation, new_activation)\n",
    "\n",
    "# użycie\n",
    "change_activation(model, nn.ReLU, nn.LeakyReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv11): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "  (maxpool1): Identity()\n",
       "  (conv21): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "  (maxpool2): Identity()\n",
       "  (left_branch): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): Identity()\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.01)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.01)\n",
       "        (relu2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.01)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.01)\n",
       "        (relu2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.01)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu1): LeakyReLU(negative_slope=0.01)\n",
       "        (relu2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.01)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.01)\n",
       "        (relu2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (right_branch): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): Identity()\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.01)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.01)\n",
       "        (relu2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.01)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.01)\n",
       "        (relu2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.01)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu1): LeakyReLU(negative_slope=0.01)\n",
       "        (relu2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.01)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.01)\n",
       "        (relu2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (main_branch): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.01)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu1): LeakyReLU(negative_slope=0.01)\n",
       "        (relu2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.01)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.01)\n",
       "        (relu2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.01)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu1): LeakyReLU(negative_slope=0.01)\n",
       "        (relu2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.01)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.01)\n",
       "        (relu2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(torch.randn(10,3,32,32), torch.randn(10,3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.modules.aux_modules import DeadReLU\n",
    "module = DeadReLU(model.left_branch, is_left_branch=True)\n",
    "module.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_true1, x_true2 = proper_x_left[:4], proper_x_right[:4]\n",
    "model(x_true1, x_true2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module.nb_of_dead_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.left_branch.named_modules())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proper_x_left[:4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clpi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
