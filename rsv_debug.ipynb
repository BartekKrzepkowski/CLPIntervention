{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, Resize, RandomAffine, RandomHorizontalFlip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.datasets_class import SplitAndAugmentDataset\n",
    "DATASET_NAME = 'dual_cifar10'\n",
    "dataset_path=os.environ['CIFAR10_PATH']\n",
    "transform1 = Compose([ToTensor()])\n",
    "transform2 = Compose([ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.CIFAR10(dataset_path, train=True, download=True)\n",
    "train_dual_augment_dataset= SplitAndAugmentDataset(train_dataset, transform1, transform2, overlap=0.0, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_held_out_data(dataset, nb_samples=1000):\n",
    "    y_data = np.array(dataset.dataset.targets)\n",
    "    num_classes = len(np.unique(y_data))\n",
    "    nb_samples_per_class = nb_samples // num_classes\n",
    "    idxs = []\n",
    "    for i in range(num_classes):\n",
    "        idxs_i = np.where(y_data == i)[0]\n",
    "        sampled_idxs_i = np.random.choice(idxs_i, size=nb_samples_per_class, replace=False)\n",
    "        idxs.append(sampled_idxs_i)\n",
    "        \n",
    "    idxs = np.concatenate(idxs)\n",
    "    selected_elements = [dataset[i] for i in idxs]\n",
    "    x_data, y_data = zip(*selected_elements)\n",
    "    x_data_left, x_data_right = zip(*x_data)\n",
    "    \n",
    "    x_data_left = torch.stack(x_data_left)\n",
    "    x_data_right = torch.stack(x_data_right)\n",
    "    y_data = torch.tensor(y_data)\n",
    "    \n",
    "    if not os.path.exists('data'):\n",
    "        os.mkdir('data')\n",
    "        \n",
    "        \n",
    "    return x_data_left, x_data_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_left, x_data_right = get_held_out_data(train_dual_augment_dataset, nb_samples=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import InterpolationMode\n",
    "from src.data.transforms import SIDE_MAP_PROPER\n",
    "\n",
    "color_jitter_transform = transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n",
    "rotation_transform = transforms.RandomRotation(degrees=10, interpolation=InterpolationMode.BILINEAR)\n",
    "random_affine = RandomAffine(degrees=0, translate=(1/8, 1/8))\n",
    "random_erasing_transform = transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=True)\n",
    "\n",
    "\n",
    "DATASET_NAME = 'dual_cifar10'\n",
    "transform_aug = lambda side: transforms.Compose([\n",
    "    # color_jitter_transform,\n",
    "    rotation_transform,\n",
    "    random_affine,\n",
    "    Normalize(*SIDE_MAP_PROPER[side][0.0]),\n",
    "    # random_erasing_transform\n",
    "])\n",
    "\n",
    "transform_aug2 = transforms.TrivialAugmentWide(interpolation=InterpolationMode.BILINEAR)\n",
    "\n",
    "transform_proper = lambda side: Compose([\n",
    "    Normalize(*SIDE_MAP_PROPER[side][0.0])\n",
    "])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def show(img, figsize=(3,3)):\n",
    "    npimg = img.numpy()\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(transform_proper('left')(x_data_left[0])), show(transform_proper('right')(x_data_right[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 10\n",
    "left, right = [], []\n",
    "for idx in range(50):\n",
    "    for _ in range(100):\n",
    "        left.append(transform_proper('left')(x_data_left[idx]))\n",
    "        right.append(transform_aug('right')(x_data_right[idx]))\n",
    "        \n",
    "    left.append(transform_proper('left')(x_data_left[idx])) \n",
    "    right.append(transform_proper('right')(x_data_right[idx]))\n",
    "\n",
    "    left.append(transform_proper('left')(x_data_left[idx])) \n",
    "    right.append(transform_proper('right')(x_data_right[idx]))\n",
    "        \n",
    "    for _ in range(100):\n",
    "        left.append(transform_aug('left')(x_data_left[idx]))\n",
    "        right.append(transform_proper('right')(x_data_right[idx]))\n",
    "\n",
    "left = torch.stack(left)\n",
    "right = torch.stack(right)\n",
    "\n",
    "# torch.save(left, f'data/{DATASET_NAME}_held_out_rsv_x_left.pt')\n",
    "# torch.save(right, f'data/{DATASET_NAME}_held_out_rsv_x_right.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "grid = torchvision.utils.make_grid(left, nrow=16)\n",
    "show(grid, figsize=(10,10))\n",
    "grid = torchvision.utils.make_grid(right, nrow=16)\n",
    "show(grid, figsize=(10,10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.utils_trainer import load_model\n",
    "from src.utils.prepare import prepare_model\n",
    "from src.modules.hooks import Hooks\n",
    "\n",
    "model_config = {'backbone_type': 'resnet18',\n",
    "                'only_features': False,\n",
    "                'batchnorm_layers': True,\n",
    "                'width_scale': 1.0,\n",
    "                'skips': True,\n",
    "                'modify_resnet': True,\n",
    "                'wheter_concate': False,\n",
    "                'overlap': 0.0,}\n",
    "model_params = {'model_config': model_config, 'num_classes': 10, 'dataset_name': 'dual_cifar10'}\n",
    "\n",
    "model = prepare_model('mm_resnet', model_params=model_params)\n",
    "\n",
    "model = load_model(model, '/raid/NFS_SHARE/home/b.krzepkowski/Github/CLPInterventions/reports2/just_run, sgd, dual_cifar10, mm_resnet_fp_0.0_lr_0.6_wd_0.0 overlap=0.0, phase4, trained with phase1=200 and phase2=0 and phase3=0/2023-09-08_03-17-16/checkpoints/model_step_epoch_200.pth')\n",
    "\n",
    "# model = load_model(model, '/raid/NFS_SHARE/home/b.krzepkowski/Github/CLPInterventions/reports/just_run, sgd, dual_cifar10, mm_resnet_fp_0.0_lr_0.55_wd_0.0 overlap=0.0, phase2, trained with phase1=0/2023-09-06_21-48-17/checkpoints/model_step_epoch_200.pth')\n",
    "# model = load_model(model, '/raid/NFS_SHARE/home/b.krzepkowski/Github/CLPInterventions/reports2/just_run, sgd, dual_cifar10, mm_resnet_fp_0.0_lr_0.6_wd_0.0_lr_lambda_1.0 overlap=0.0, phase1, tak naprawdÄ™ 2, phase1=0/2023-09-11_18-39-51/checkpoints/model_step_epoch_200.pth')\n",
    "# model = load_model(model, '/raid/NFS_SHARE/home/b.krzepkowski/Github/CLPInterventions/reports/just_run, sgd, dual_cifar10, mm_resnet_fp_0.0_lr_0.6_wd_0.0 overlap=0.0, phase4, trained with phase1=80 and phase2=0 and phase3=0/2023-09-07_19-44-48/checkpoints/model_step_epoch_200.pth')\n",
    "# model = load_model(model, '/raid/NFS_SHARE/home/b.krzepkowski/Github/CLPInterventions/reports/just_run, sgd, dual_cifar10, mm_resnet_fp_0.0_lr_0.6_wd_0.0 overlap=0.0, phase4, trained with phase1=80 and phase2=0 and phase3=40/2023-09-07_19-52-53/checkpoints/model_step_epoch_200.pth')\n",
    "# model = load_model(model, '/raid/NFS_SHARE/home/b.krzepkowski/Github/CLPInterventions/reports/just_run, sgd, dual_cifar10, mm_resnet_fp_0.0_lr_0.6_wd_0.0 overlap=0.0, phase4, trained with phase1=80 and phase2=0 and phase3=38/2023-09-11_10-23-35/checkpoints/model_step_epoch_160.pth')\n",
    "# model = load_model(model, '/raid/NFS_SHARE/home/b.krzepkowski/Github/CLPInterventions/reports/just_run, sgd, dual_cifar10, mm_resnet_fp_0.0_lr_0.6_wd_0.0 overlap=0.0, phase4, trained with phase1=80 and phase2=0 and phase3=37/2023-09-11_00-25-08/checkpoints/model_step_epoch_200.pth', device=device)\n",
    "\n",
    "hooks_rsv = Hooks(model.net3, logger=None, callback_type='rsv')\n",
    "hooks_rsv.register_hooks(model.net3, [torch.nn.Conv2d, torch.nn.Linear])\n",
    "hooks_rsv.enable()\n",
    "hooks_rsv.callback.group_size = 202\n",
    "\n",
    "y = model(left, right,\n",
    "          left_branch_intervention=None,\n",
    "          right_branch_intervention=None,\n",
    "          enable_left_branch=True,\n",
    "          enable_right_branch=True)\n",
    "\n",
    "data = hooks_rsv.gather_data()\n",
    "hooks_rsv.reset()\n",
    "len(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deficit=0\n",
    "import seaborn as sns\n",
    "# data = [1, 2, 2, 3, 3, 3, 4, 4, 5]\n",
    "data1 = torch.stack(data[0]).reshape(-1).detach().cpu().numpy()\n",
    "data1.shape\n",
    "# data1 = torch.stack(data[0])\n",
    "\n",
    "data1.mean(), data1.std(), np.median(data1)\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "z = 2.576\n",
    "mean = data1.mean()\n",
    "std_dev = z * data1.std(ddof=1) / np.sqrt(len(data1))\n",
    "median = np.median(data1)\n",
    "mean,std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# UtwÃ³rz obiekt subplotu z wykresem typu histogram\n",
    "fig = go.Figure()\n",
    "\n",
    "# Dodaj histogram do subplotu\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=data1,\n",
    "        xbins=dict(start=-1, end=1),\n",
    "        nbinsx=200,\n",
    "        showlegend=False,\n",
    "        marker=dict(\n",
    "            color='beige',\n",
    "            line=dict(\n",
    "                color='black',  # Kolor linii miÄ™dzy binami\n",
    "                width=.2  # SzerokoÅ›Ä‡ linii miÄ™dzy binami\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "y_max = max(np.histogram(data1, bins=200)[0]) * 1.05\n",
    "fig.add_trace(go.Scatter(x=[mean, mean], y=[0, y_max], mode='lines', name=f'Mean={mean:.3f}', line=dict(color='chocolate')))\n",
    "fig.add_trace(go.Scatter(x=[median, median], y=[0, y_max], mode='lines', name=f'Median={median:.3f}', line=dict(color='darkorange')))\n",
    "\n",
    "fig.update_layout(\n",
    "    width=600,\n",
    "    height=500,\n",
    "    yaxis=dict(showticklabels=False),\n",
    "    legend=dict(\n",
    "    orientation=\"h\",\n",
    "    yanchor=\"bottom\",\n",
    "    y=1.02,\n",
    "    xanchor=\"right\",\n",
    "    x=1,\n",
    "    title_text=\"Phase 1 lasted 200 epochs\",\n",
    "    title_font=dict(size=20)\n",
    "))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Ustawienie siatki wykresÃ³w\n",
    "fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(15, 5))\n",
    "\n",
    "for i in range(10):\n",
    "    row = i // 5\n",
    "    col = i % 5\n",
    "    values = torch.stack(data[i]).reshape(-1).detach().cpu().numpy()\n",
    "    sns.histplot(values, bins=100, ax=axes[row, col])\n",
    "    axes[row, col].set_title(f'Histogram dla listy {i + 1}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.utils_trainer import load_model\n",
    "from src.utils.prepare import prepare_model\n",
    "from src.modules.hooks import Hooks\n",
    "\n",
    "def get_data(model_path, x_data_left, x_data_right):\n",
    "    model_config = {'backbone_type': 'resnet18',\n",
    "                'only_features': False,\n",
    "                'batchnorm_layers': True,\n",
    "                'width_scale': 1.0,\n",
    "                'skips': True,\n",
    "                'modify_resnet': True,\n",
    "                'wheter_concate': False,\n",
    "                'overlap': 0.0,}\n",
    "    model_params = {'model_config': model_config, 'num_classes': 10, 'dataset_name': 'dual_cifar10'}\n",
    "    model = prepare_model('mm_resnet', model_params=model_params)\n",
    "    model = load_model(model, model_path)\n",
    "    \n",
    "    hooks_rsv = Hooks(model.net3, logger=None, callback_type='rsv')\n",
    "    hooks_rsv.register_hooks(model.net3, [torch.nn.Conv2d, torch.nn.Linear])\n",
    "    hooks_rsv.enable()\n",
    "    hooks_rsv.callback.group_size = 202\n",
    "    _ = model(x_data_left, x_data_right,\n",
    "            left_branch_intervention=None,\n",
    "            right_branch_intervention=None,\n",
    "            enable_left_branch=True,\n",
    "            enable_right_branch=True)\n",
    "\n",
    "    data = hooks_rsv.gather_data()\n",
    "    data = torch.stack(data[0]).reshape(-1).detach().cpu().numpy()\n",
    "    hooks_rsv.reset()\n",
    "    return data\n",
    "\n",
    "path1 = '/raid/NFS_SHARE/home/b.krzepkowski/Github/CLPInterventions/reports2/just_run, sgd, dual_cifar10, mm_resnet_fp_0.0_lr_0.6_wd_0.0 overlap=0.0, phase4, trained with phase1=0 and phase2=0 and phase3=0/2023-09-07_14-22-54/checkpoints/model_step_epoch_200.pth'\n",
    "path2 = '/raid/NFS_SHARE/home/b.krzepkowski/Github/CLPInterventions/reports2/just_run, sgd, dual_cifar10, mm_resnet_fp_0.0_lr_0.6_wd_0.0 overlap=0.0, phase4, trained with phase1=40 and phase2=0 and phase3=0/2023-09-07_12-03-42/checkpoints/model_step_epoch_200.pth'\n",
    "path3 = '/raid/NFS_SHARE/home/b.krzepkowski/Github/CLPInterventions/reports2/just_run, sgd, dual_cifar10, mm_resnet_fp_0.0_lr_0.6_wd_0.0 overlap=0.0, phase4, trained with phase1=120 and phase2=0 and phase3=0/2023-09-07_22-35-39/checkpoints/model_step_epoch_200.pth'\n",
    "path4 = '/raid/NFS_SHARE/home/b.krzepkowski/Github/CLPInterventions/reports2/just_run, sgd, dual_cifar10, mm_resnet_fp_0.0_lr_0.6_wd_0.0 overlap=0.0, phase4, trained with phase1=200 and phase2=0 and phase3=0/2023-09-08_03-17-16/checkpoints/model_step_epoch_200.pth'\n",
    "\n",
    "\n",
    "path5 = '/raid/NFS_SHARE/home/b.krzepkowski/Github/CLPInterventions/reports2/just_run, sgd, dual_cifar10, mm_resnet_fp_0.0_lr_0.55_wd_0.0 overlap=0.0, phase4, trained with phase1=40 and phase2=200 and phase3=60/2023-09-08_19-27-35/checkpoints/model_step_epoch_200.pth'\n",
    "path6 = '/raid/NFS_SHARE/home/b.krzepkowski/Github/CLPInterventions/reports2/just_run, sgd, dual_cifar10, mm_resnet_fp_0.0_lr_0.55_wd_0.0 overlap=0.0, phase4, trained with phase1=120 and phase2=200 and phase3=80/2023-09-09_02-40-19/checkpoints/model_step_epoch_200.pth'\n",
    "path7 = '/raid/NFS_SHARE/home/b.krzepkowski/Github/CLPInterventions/reports2/just_run, sgd, dual_cifar10, mm_resnet_fp_0.0_lr_0.55_wd_0.0 overlap=0.0, phase4, trained with phase1=200 and phase2=200 and phase3=80/2023-09-09_09-41-02/checkpoints/model_step_epoch_200.pth'\n",
    "\n",
    "path8 = '/raid/NFS_SHARE/home/b.krzepkowski/Github/CLPInterventions/reports2/just_run, sgd, dual_cifar10, mm_resnet_fp_0.0_lr_0.55_wd_0.0 overlap=0.0, phase4, trained with phase1=40 and phase2=200 and phase3=80/2023-09-08_19-53-33/checkpoints/model_step_epoch_200.pth'\n",
    "path9 = '/raid/NFS_SHARE/home/b.krzepkowski/Github/CLPInterventions/reports2/just_run, sgd, dual_cifar10, mm_resnet_fp_0.0_lr_0.55_wd_0.0 overlap=0.0, phase4, trained with phase1=120 and phase2=200 and phase3=120/2023-09-09_02-49-34/checkpoints/model_step_epoch_200.pth'\n",
    "path10 = '/raid/NFS_SHARE/home/b.krzepkowski/Github/CLPInterventions/reports2/just_run, sgd, dual_cifar10, mm_resnet_fp_0.0_lr_0.55_wd_0.0 overlap=0.0, phase4, trained with phase1=200 and phase2=200 and phase3=120/2023-09-09_09-41-02/checkpoints/model_step_epoch_200.pth'\n",
    "\n",
    "# path5 = '/raid/NFS_SHARE/home/b.krzepkowski/Github/CLPInterventions/reports2/just_run, sgd, dual_cifar10, mm_resnet_fp_0.0_lr_0.6_wd_0.0 overlap=0.0, phase4, trained with phase1=40 and phase2=0 and phase3=20/2023-09-07_12-03-54/checkpoints/model_step_epoch_200.pth'\n",
    "# path6 = '/raid/NFS_SHARE/home/b.krzepkowski/Github/CLPInterventions/reports2/just_run, sgd, dual_cifar10, mm_resnet_fp_0.0_lr_0.6_wd_0.0 overlap=0.0, phase4, trained with phase1=120 and phase2=0 and phase3=20/2023-09-07_22-35-42/checkpoints/model_step_epoch_200.pth'\n",
    "# path7 = '/raid/NFS_SHARE/home/b.krzepkowski/Github/CLPInterventions/reports2/just_run, sgd, dual_cifar10, mm_resnet_fp_0.0_lr_0.6_wd_0.0 overlap=0.0, phase4, trained with phase1=200 and phase2=0 and phase3=40/2023-09-08_03-22-35/checkpoints/model_step_epoch_200.pth'\n",
    "\n",
    "path11 = '/raid/NFS_SHARE/home/b.krzepkowski/Github/CLPInterventions/reports2/just_run, sgd, dual_cifar10, mm_resnet_fp_0.0_lr_0.6_wd_0.0 overlap=0.0, phase4, trained with phase1=80 and phase2=0 and phase3=38/2023-09-11_10-23-35/checkpoints/model_step_epoch_200.pth'\n",
    "# path12 = '/raid/NFS_SHARE/home/b.krzepkowski/Github/CLPInterventions/reports2/just_run, sgd, dual_cifar10, mm_resnet_fp_0.0_lr_0.6_wd_0.0 overlap=0.0, phase4, trained with phase1=80 and phase2=0 and phase3=38/2023-09-11_10-23-35/checkpoints/model_step_epoch_200.pth'\n",
    "\n",
    "paths = [path1, path2, path3, path4, path5, path6, path7, path8, path9, path10, path11]\n",
    "data = []\n",
    "for path in paths:\n",
    "    data.append(get_data(path, left, right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0 = np.concatenate([data[0], np.clip(np.random.randn(20000)*2e-1 - 0.21, a_min=-1, a_max=1)])\n",
    "# data[-1] = data0\n",
    "# data.append(data0)\n",
    "# plt.hist(np.clip(np.random.randn(100)*1e-1 - 0.03, a_min=-1, a_max=1), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "\n",
    "# epochs1 = [0, 40, 120, 200]\n",
    "\n",
    "# epochs2 = {\n",
    "#     40: [20, 20, 40],\n",
    "#     120: [],\n",
    "#     200: []\n",
    "# }\n",
    "# data = [np.random.randn(100) for _ in range(16)]\n",
    "subplot_titles = ['Phase 1 = 0 epochs', 'Phase 1 = 40 epochs', 'Phase 120 = 0 epochs', 'Phase 1 = 200 epochs',\n",
    "                  '', 'Phase 1 = 40 epochs, Phase 3 = 60 epochs', 'Phase 1 = 120 epochs, Phase 3 = 80 epochs', 'Phase 1 = 200 epochs, Phase 3 = 80 epochs',\n",
    "                  '', 'Phase 1 = 40 epochs, Phase 3 = 80 epochs', 'Phase 1 = 120 epochs, Phase 3 = 120 epochs', 'Phase 1 = 200 epochs, Phase 3 = 120 epochs'\n",
    "                  '','', 'Phase 1 = 40 epochs, Phase 3 = 73 epochs', 'Phase 1 = 120 epochs, Phase 3 = 96 epochs']\n",
    "\n",
    "phase_text = ['0', '40', '120', '200',\n",
    "              '40-60', '120-80', '200-80',\n",
    "              '40-80', '120-120', '200-120'\n",
    "              '40-73', '120-96', '200-40']\n",
    "\n",
    "fig = make_subplots(rows=4, cols=4, subplot_titles=subplot_titles)\n",
    "\n",
    "font_size = 22.5\n",
    "for annotation in fig['layout']['annotations']: \n",
    "    annotation['font'] = dict(size=font_size)\n",
    "\n",
    "aux = [0, -1, -2, -3]\n",
    "\n",
    "# Dodaj histogramy do kaÅ¼dego subplota (z wyjÄ…tkiem pierwszej kolumny, oprÃ³cz pierwszego wiersza)\n",
    "for r in range(1, 5):\n",
    "    for c in range(1, 5):\n",
    "        if (c != 1 or r == 1) and (c != 4 or r != 4):\n",
    "            idx = (r - 1) * 4 + c - 1 + aux[r-1]\n",
    "            print(idx)\n",
    "            data1 = data[idx]\n",
    "            mean_val = np.mean(data1)\n",
    "            median_val = np.median(data1)\n",
    "            y_max = max(np.histogram(data1, bins=100)[0]) * 1.05\n",
    "            \n",
    "            phase = phase_text[idx]\n",
    "            \n",
    "            fig.add_trace(go.Histogram(x=data1,\n",
    "                                       showlegend=False,\n",
    "                                       legendgroup=phase,\n",
    "                                       nbinsx=100,\n",
    "                                       xbins=dict(start=-1, end=1),\n",
    "                                       name=f'Hist {phase}',\n",
    "                                       marker=dict(\n",
    "            color='beige',\n",
    "            line=dict(\n",
    "                color='black',  # Kolor linii miÄ™dzy binami\n",
    "                width=.2  # SzerokoÅ›Ä‡ linii miÄ™dzy binami\n",
    "            )\n",
    "        )),row=r, col=c)\n",
    "            fig.add_shape(go.layout.Shape(type=\"line\", x0=mean_val, x1=mean_val, y0=0, y1=y_max, line=dict(color=\"chocolate\"), line_width=2), row=r, col=c)\n",
    "            fig.add_shape(go.layout.Shape(type=\"line\", x0=median_val, x1=median_val, y0=0, y1=y_max, line=dict(color=\"darkorange\"), line_width=2), row=r, col=c)\n",
    "\n",
    "            # Dodaj \"pusty\" Å›lad do stworzenia oddzielnej legendy\n",
    "            fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', line=dict(color='chocolate', width=2), name=f'Mean  = {mean_val:.2f} ({phase})', legendgroup=phase))\n",
    "            fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', line=dict(color='darkorange', width=2), name=f'Median  = {median_val:.2f} ({phase})', legendgroup=phase))\n",
    "\n",
    "# Aktualizacja ukÅ‚adu dla zakresu osi x, ukrycia osi y oraz wymiarÃ³w\n",
    "fig.update_xaxes(range=[-1, 1], tickfont=dict(size=20))\n",
    "fig.update_yaxes(showticklabels=False)\n",
    "fig.update_layout(height=4*600, width=4*500, legend_font_size=40, title_font_size=40, legend=dict(x=0, y=0.5, font=dict(size=26), bgcolor='rgba(255,255,255,0.5)', bordercolor='rgba(0,0,0,0.2)',borderwidth=1))\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# PrzykÅ‚adowe dane\n",
    "data = [np.random.randn(100) for _ in range(16)]\n",
    "\n",
    "# Tworzenie figury\n",
    "fig = go.Figure()\n",
    "\n",
    "# Zdefiniuj wartoÅ›ci x i y dla subplotÃ³w\n",
    "x_domains = [(i*0.25, (i+1)*0.25) for i in range(4)]\n",
    "y_domains = [(i*0.25, (i+1)*0.25) for i in range(4)][::-1]\n",
    "\n",
    "# Rysowanie histogramÃ³w\n",
    "for i, x_domain in enumerate(x_domains):\n",
    "    for j, y_domain in enumerate(y_domains):\n",
    "        if i == 0 and j == 0: # Pierwszy rysunek (lewy gÃ³rny rÃ³g)\n",
    "            hist_data = data[0]\n",
    "            fig.add_trace(\n",
    "                go.Histogram(x=hist_data, histnorm='percent', name=f\"Histogram {i+j*4}\", xaxis=f'x{i+1}', yaxis=f'y{j+1}')\n",
    "            )\n",
    "            mean_val = np.mean(hist_data)\n",
    "            median_val = np.median(hist_data)\n",
    "            max_bin_height = max(np.histogram(hist_data, bins=10)[0])\n",
    "\n",
    "            fig.add_shape(\n",
    "                dict(type=\"line\", x0=mean_val, x1=mean_val, y0=0, y1=max_bin_height, yref=f'y{j+1}', xref=f'x{i+1}', line=dict(color=\"Blue\", width=2))\n",
    "            )\n",
    "            fig.add_shape(\n",
    "                dict(type=\"line\", x0=median_val, x1=median_val, y0=0, y1=max_bin_height, yref=f'y{j+1}', xref=f'x{i+1}', line=dict(color=\"Red\", width=2))\n",
    "            )\n",
    "\n",
    "        elif i > 0:\n",
    "            hist_data = data[i+j*4]\n",
    "            fig.add_trace(\n",
    "                go.Histogram(x=hist_data, histnorm='percent', showlegend=False, xaxis=f'x{i+1}', yaxis=f'y{j+1}')\n",
    "            )\n",
    "            mean_val = np.mean(hist_data)\n",
    "            median_val = np.median(hist_data)\n",
    "            max_bin_height = max(np.histogram(hist_data, bins=10)[0])\n",
    "\n",
    "            fig.add_shape(\n",
    "                dict(type=\"line\", x0=mean_val, x1=mean_val, y0=0, y1=max_bin_height, yref=f'y{j+1}', xref=f'x{i+1}', line=dict(color=\"Blue\", width=2))\n",
    "            )\n",
    "            fig.add_shape(\n",
    "                dict(type=\"line\", x0=median_val, x1=median_val, y0=0, y1=max_bin_height, yref=f'y{j+1}', xref=f'x{i+1}', line=dict(color=\"Red\", width=2))\n",
    "            )\n",
    "\n",
    "# Aktualizacja layoutu\n",
    "fig.update_layout(\n",
    "    xaxis_domain=x_domains[0], yaxis_domain=y_domains[0], xaxis2_domain=x_domains[1], yaxis2_domain=y_domains[0],\n",
    "    xaxis3_domain=x_domains[2], yaxis3_domain=y_domains[0], xaxis4_domain=x_domains[3], yaxis4_domain=y_domains[0],\n",
    "    xaxis5_domain=x_domains[0], yaxis5_domain=y_domains[1], xaxis6_domain=x_domains[1], yaxis6_domain=y_domains[1],\n",
    "    xaxis7_domain=x_domains[2], yaxis7_domain=y_domains[1], xaxis8_domain=x_domains[3], yaxis8_domain=y_domains[1],\n",
    "    xaxis9_domain=x_domains[0], yaxis9_domain=y_domains[2], xaxis10_domain=x_domains[1], yaxis10_domain=y_domains[2],\n",
    "    xaxis11_domain=x_domains[2], yaxis11_domain=y_domains[2], xaxis12_domain=x_domains[3], yaxis12_domain=y_domains[2],\n",
    "    xaxis13_domain=x_domains[0], yaxis13_domain=y_domains[3], xaxis14_domain=x_domains[1], yaxis14_domain=y_domains[3],\n",
    "    xaxis15_domain=x_domains[2], yaxis15_domain=y_domains[3], xaxis16_domain=x_domains[3], yaxis16_domain=y_domains[3],\n",
    "    margin=dict(l=20, r=20, t=20, b=20),\n",
    "    paper_bgcolor=\"LightSteelBlue\",\n",
    ")\n",
    "\n",
    "# Aktualizacja osi X\n",
    "for i in range(4):\n",
    "    fig.update_layout({f'xaxis{i+1}': dict(range=[-1,1], showgrid=False)})\n",
    "    fig.update_layout({f'yaxis{i+1}': dict(showticklabels=False)})\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# PrzykÅ‚adowe dane\n",
    "data2 = [np.random.randn(100) for _ in range(16)]\n",
    "mean_vals = [np.mean(d) for d in data2]\n",
    "median_vals = [np.median(d) for d in data2]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Dodaj kategorie do legendy\n",
    "categories = ['Category 1', 'Category 2']\n",
    "for cat in categories:\n",
    "    fig.add_trace(go.Scatter(x=[None], y=[None], mode='lines', line={'width': 0}, name=cat, legendgroup=cat))\n",
    "\n",
    "# Dodaj rzeczywiste Å›lady z kategoriami\n",
    "for i, d in enumerate(data2):\n",
    "    if i < 8:\n",
    "        legendgroup = 'Category 1'\n",
    "    else:\n",
    "        legendgroup = 'Category 2'\n",
    "    \n",
    "    fig.add_trace(go.Histogram(x=d, legendgroup=legendgroup, showlegend=False))\n",
    "    fig.add_trace(go.Scatter(x=[mean_vals[i]], y=[0], mode='markers', legendgroup=legendgroup, showlegend=False))\n",
    "    fig.add_trace(go.Scatter(x=[median_vals[i]], y=[0], mode='markers', legendgroup=legendgroup, showlegend=False))\n",
    "\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clpi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
